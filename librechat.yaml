version: 1.1.5

cache: true

# Custom endpoint configuration
endpoints:
  custom:
    - name: "Ollama via LiteLLM"
      apiKey: "sk-1234"
      baseURL: "http://litellm:4000/v1"
      models:
        default:
          - "mistral"
          - "gpt-oss-20b"
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral"
      summarize: false
      summaryModel: "mistral"
      forcePrompt: false
      modelDisplayLabel: "Ollama (via LiteLLM)"
      iconURL: "https://raw.githubusercontent.com/ollama/ollama/main/docs/images/ollama.png"
      addParams:
        max_tokens: 4000
        temperature: 0.7
        top_p: 0.9
        frequency_penalty: 0
        presence_penalty: 0

# Interface configuration
interface:
  privacyPolicy:
    externalUrl: ""
    openNewTab: true
  termsOfService:
    externalUrl: ""
    openNewTab: true

# Registration and authentication
# Note: Social logins are configured via environment variables

# File handling
fileConfig:
  disabled: false
  endpoints:
    custom:
      disabled: false
      fileLimit: 5
      fileSizeLimit: 10
      totalSizeLimit: 50
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"

# Rate limiting
rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60
  conversationsImport:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60